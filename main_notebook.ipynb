{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "#!pip install sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import pickle\n",
    "\n",
    "home_dir = '~/Documents/thesis/datasets/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_subsample(x, y, subsample_size=1.0):\n",
    "\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            this_xs = this_xs.reindex(np.random.permutation(this_xs.index))\n",
    "\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "\n",
    "    xs = pd.concat(xs)\n",
    "    ys = pd.Series(data=np.concatenate(ys),name='target')\n",
    "\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(x):\n",
    "    return (x - x.min(0)) / x.ptp(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_columns_panda(pandaDataframe, blacklist):\n",
    "    for element in blacklist:\n",
    "        del pandaDataframe[element]\n",
    "    return pandaDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data = data.replace(\"na\", 0)\n",
    "    data = data.replace(\"neg\", 0)\n",
    "    data = data.replace(\"pos\", 1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_data(with_undersampling=False):\n",
    "    \n",
    "    # our training and test datasets\n",
    "    X_train = pd.read_csv(home_dir + 'scania/training_set_new.csv')\n",
    "    X_test = pd.read_csv(home_dir + 'scania/test_set_new.csv') \n",
    "    \n",
    "    # \"live data\" dataset\n",
    "    live_test = pd.read_csv(home_dir + 'aps_failure_test_set.csv') \n",
    "    \n",
    "    X_train = preprocess_data(X_train)\n",
    "    X_test = preprocess_data(X_test)\n",
    "    live_test = preprocess_data(live_test)\n",
    "    \n",
    "    y_train = X_train.iloc[:, 0]  # First column in labels\n",
    "    y_test = X_test.iloc[:, 0]  # First column in labels\n",
    "    y_live_test = live_test.iloc[:, 0]  # First column in labels\n",
    "\n",
    "    X_train = X_train.drop(X_train.columns[0], axis=1)  # delete first column of xtrain\n",
    "    X_test = X_test.drop(X_test.columns[0], axis=1)  # delete first column of xtest\n",
    "    live_test = live_test.drop(live_test.columns[0], axis=1)  # delete first column of xtest\n",
    "    \n",
    "    if with_undersampling:\n",
    "        X_train, y_train = balanced_subsample(X_train, y_train)\n",
    "        \n",
    "    return X_train, X_test, live_test, y_train, y_test, y_live_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions_to_file(filename, data):\n",
    "    f = open(filename, 'w')\n",
    "    f.write('id,label\\n')\n",
    "    i = 1\n",
    "    for item in data:\n",
    "        f.write('%s' % i)\n",
    "        f.write(',')\n",
    "        f.write('%s' % int(item))\n",
    "        f.write('\\n')\n",
    "        i = i+1\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cost(predictions, X_train, X_test, y_train, y_test):\n",
    "    cost_1_instances = 0\n",
    "    cost_2_instances = 0\n",
    "    normal_correct = 0\n",
    "    anomaly_correct = 0\n",
    "    for i in range(0, len(predictions)):\n",
    "        if predictions[i] == 0 and y_test[i] == 1:  # He predicted normal but it was anomaly\n",
    "            cost_2_instances += 1\n",
    "        elif predictions[i] == 1 and y_test[i] == 0:  # He predicted anomaly but it was normal\n",
    "            cost_1_instances += 1\n",
    "        elif predictions[i] == 0 and y_test[i] == 0: # He predicted normal and it was normal\n",
    "            normal_correct += 1\n",
    "        elif predictions[i] == 1 and y_test[i] == 1: # He predicted anomaly and it was anomaly\n",
    "            anomaly_correct += 1\n",
    "\n",
    "    print ((\"cost_1_instances are {}\".format(cost_1_instances)))\n",
    "    print ((\"cost_2_instances are {}\".format(cost_2_instances)))\n",
    "    print ((\"Correct normal predictions are {}\".format(normal_correct)))\n",
    "    print ((\"Correct anomaly predictions are {}\".format(anomaly_correct)))\n",
    "    print ((\"Total Cost is {}\".format(10*cost_1_instances + 500*cost_2_instances)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X_train,y_train, num_of_features, X_test, y_test):\n",
    "# Build RF classifier to use in feature selection\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "    #create new scoring parameter based on cost function\n",
    "    cost = make_scorer( find_cost, greater_is_better= False)\n",
    "    # Build step forward feature selection\n",
    "    sfs1 = sfs(knn,\n",
    "               k_features= num_of_features,\n",
    "               forward=True,\n",
    "               floating=False,\n",
    "               verbose=2,\n",
    "               scoring=cost,\n",
    "               cv=0)\n",
    "\n",
    "    # Perform SFFS\n",
    "    sfs1 = sfs1.fit(X_train, y_train)\n",
    "    predictions = sfs1.predict(X_test)\n",
    "\n",
    "    feat_cols = list(sfs1.k_feature_idx_)\n",
    "    print(feat_cols)\n",
    "    \n",
    "    return feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_classifier(use_training, clf, X_train, X_test, y_train, y_test, name):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    # predictions = np.round(predictions)\n",
    "\n",
    "    \n",
    "    \n",
    "    if  use_training:\n",
    "        prediction_prob = clf.predict_proba(X_test)\n",
    "       \n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "        for pr in prediction_prob:\n",
    "            if pr[0] > 0.95:\n",
    "                predictions.append(0)  # Neg\n",
    "            else:\n",
    "                predictions.append(1)  # Pos\n",
    "\n",
    "    accuracy = 0\n",
    "    for i in range(0, len(predictions)):\n",
    "        if predictions[i] == y_test[i]:\n",
    "            accuracy +=1\n",
    "\n",
    "\n",
    "    conf_mat = confusion_matrix(y_test, predictions)        \n",
    "    average_precision = average_precision_score(y_test, predictions)\n",
    "\n",
    "    #find average precision recall\n",
    "    print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "    precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "\n",
    "    #plot precision recall\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "              average_precision))\n",
    "\n",
    "    write_predictions_to_file(name + '_output.csv.dat', y_test)\n",
    "    find_cost(predictions, X_train, X_test, y_train, y_test)\n",
    "    # print (\"Accuracy of {} is {} %\".format(name, round((accuracy)*100, 5)))\n",
    "\n",
    "    return predictions, accuracy/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data from the csv files\n",
    "X_train, X_test, live_test, y_train, y_test, y_live_test = reset_data(with_undersampling=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.36\n",
      "cost_1_instances are 195\n",
      "cost_2_instances are 67\n",
      "Correct normal predictions are 14555\n",
      "Correct anomaly predictions are 183\n",
      "Total Cost is 35450\n",
      "Accuracy of KNeighborsClassifier is 98.25333 %\n",
      "KNN results on live data\n",
      "Average precision-recall score: 0.41\n",
      "cost_1_instances are 55\n",
      "cost_2_instances are 184\n",
      "Correct normal predictions are 15570\n",
      "Correct anomaly predictions are 191\n",
      "Total Cost is 92550\n",
      "Accuracy of KNeighborsClassifier live is 98.50625 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4cafcf6978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define \"classifiers\" to be used\n",
    "\n",
    "classifiers = {\n",
    "\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(3)\n",
    "}\n",
    "\n",
    "# executing each classifier\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    #feat_cols = feature_selection(X_train,y_train, i,  X_test, y_test)\n",
    "    feat_cols = [8, 37, 38, 70, 75]\n",
    "\n",
    "    x_train_less_feat = X_train.iloc[:, feat_cols]\n",
    "    x_test_less_feat = X_test.iloc[:, feat_cols]\n",
    "    live_test = live_test.iloc[:, feat_cols]\n",
    "    \n",
    "    # predictions after feature reduction\n",
    "    predictions_tocompare, accuracy_tocompare = execute_classifier(True, classifier, x_train_less_feat, x_test_less_feat, y_train, y_test, name=name)\n",
    "    print(\"Accuracy of {} is {} %\".format(name, round((accuracy_tocompare)*100, 5)))\n",
    "    \n",
    "    print(\"KNN results on live data\")\n",
    "    predictions_live, accuracy_live = execute_classifier(False, classifier, x_train_less_feat, live_test, y_train, y_live_test, name=name)\n",
    "    print (\"Accuracy of {} live is {} %\".format(name, round((accuracy_live)*100, 5)))\n",
    "\n",
    "    # new model is trained with live data \n",
    "    # missing test data for the new model\n",
    "    #predictions_eval_model, accuracy_eval_model = execute_classifier(True, classifier, x2_train_live, ???,  y2_test, ???, name=name)\n",
    "\n",
    "    #print (\"Accuracy of {} the evaluation model is {} %\".format(name, round((accuracy_eval_model)*100, 5)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 170)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
