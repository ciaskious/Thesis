{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "#!pip install sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import pickle\n",
    "\n",
    "home_dir = '~/Documents/thesis/datasets/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_subsample(x, y, subsample_size=1.0):\n",
    "\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            this_xs = this_xs.reindex(np.random.permutation(this_xs.index))\n",
    "\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "\n",
    "    xs = pd.concat(xs)\n",
    "    ys = pd.Series(data=np.concatenate(ys),name='target')\n",
    "\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(x):\n",
    "    return (x - x.min(0)) / x.ptp(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_columns_panda(pandaDataframe, blacklist):\n",
    "    for element in blacklist:\n",
    "        del pandaDataframe[element]\n",
    "    return pandaDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data = data.replace(\"na\", 0)\n",
    "    data = data.replace(\"neg\", 0)\n",
    "    data = data.replace(\"pos\", 1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_data(with_undersampling=False):\n",
    "    \n",
    "    X_train = pd.read_csv(home_dir + 'scania/training_set_new.csv')\n",
    "    X_test = pd.read_csv(home_dir + 'scania/test_set_new.csv')  \n",
    "    \n",
    "    X_train = preprocess_data(X_train)\n",
    "    X_test = preprocess_data(X_test)\n",
    "\n",
    "    y_train = X_train.iloc[:, 0]  # First column in labels\n",
    "    y_test = X_test.iloc[:, 0]  # First column in labels\n",
    "\n",
    "    X_train = X_train.drop(X_train.columns[0], axis=1)  # delete first column of xtrain\n",
    "    X_test = X_test.drop(X_test.columns[0], axis=1)  # delete first column of xtest\n",
    "\n",
    "    if with_undersampling:\n",
    "        X_train, y_train = balanced_subsample(X_train, y_train)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions_to_file(filename, data):\n",
    "    f = open(filename, 'w')\n",
    "    f.write('id,label\\n')\n",
    "    i = 1\n",
    "    for item in data:\n",
    "        f.write('%s' % i)\n",
    "        f.write(',')\n",
    "        f.write('%s' % int(item))\n",
    "        f.write('\\n')\n",
    "        i = i+1\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cost(predictions, X_train, X_test, y_train, y_test):\n",
    "    cost_1_instances = 0\n",
    "    cost_2_instances = 0\n",
    "    normal_correct = 0\n",
    "    anomaly_correct = 0\n",
    "    for i in range(0, len(predictions)):\n",
    "        if predictions[i] == 0 and y_test[i] == 1:  # He predicted normal but it was anomaly\n",
    "            cost_2_instances += 1\n",
    "        elif predictions[i] == 1 and y_test[i] == 0:  # He predicted anomaly but it was normal\n",
    "            cost_1_instances += 1\n",
    "        elif predictions[i] == 0 and y_test[i] == 0: # He predicted normal and it was normal\n",
    "            normal_correct += 1\n",
    "        elif predictions[i] == 1 and y_test[i] == 1: # He predicted anomaly and it was anomaly\n",
    "            anomaly_correct += 1\n",
    "\n",
    "    print ((\"cost_1_instances are {}\".format(cost_1_instances)))\n",
    "    print ((\"cost_2_instances are {}\".format(cost_2_instances)))\n",
    "    print ((\"Correct normal predictions are {}\".format(normal_correct)))\n",
    "    print ((\"Correct anomaly predictions are {}\".format(anomaly_correct)))\n",
    "    print ((\"Total Cost is {}\".format(10*cost_1_instances + 500*cost_2_instances)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X_train,y_train):\n",
    "# Build RF classifier to use in feature selection\n",
    "    clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "    # Build step forward feature selection\n",
    "    sfs1 = sfs(clf,\n",
    "               k_features=50,\n",
    "               forward=True,\n",
    "               floating=False,\n",
    "               verbose=2,\n",
    "               scoring='accuracy',\n",
    "               cv=10)\n",
    "\n",
    "    # Perform SFFS\n",
    "    sfs1 = sfs1.fit(X_train, y_train)\n",
    "    \n",
    "    feat_cols = list(sfs1.k_feature_idx_)\n",
    "    print(feat_cols)\n",
    "    \n",
    "    return feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_classifier(use_training, clf, X_train, X_test, y_train, y_test, feat_cols, name):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    # predictions = np.round(predictions)\n",
    "    clf.fit(X_train[:, feat_cols], y_train)\n",
    "\n",
    "    y_train_pred = clf.predict(X_train[:, feat_cols])\n",
    "    print('Training accuracy on selected features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "    y_test_pred = clf.predict(X_test[:, feat_cols])\n",
    "    print('Testing accuracy on selected features: %.3f' % acc(y_test, y_test_pred))\n",
    "    \n",
    "    \n",
    "    if not use_training:\n",
    "        return predictions\n",
    "    else:\n",
    "        prediction_prob = clf.predict_proba(X_test)\n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "        for pr in prediction_prob:\n",
    "            if pr[0] > 0.95:\n",
    "                predictions.append(0)  # Neg\n",
    "            else:\n",
    "                predictions.append(1)  # Pos\n",
    "\n",
    "        accuracy = 0\n",
    "        for i in range(0, len(predictions)):\n",
    "            if predictions[i] == y_test[i]:\n",
    "                accuracy +=1\n",
    "                \n",
    "        average_precision = average_precision_score(y_test, predictions)\n",
    "        \n",
    "        #find average precision recall\n",
    "        print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "\n",
    "        #plot precision recall\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "\n",
    "        plt.step(recall, precision, color='b', alpha=0.2,\n",
    "                 where='post')\n",
    "        plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                         color='b')\n",
    "\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "                  average_precision))\n",
    "\n",
    "        write_predictions_to_file(name + '_output.csv.dat', y_test)\n",
    "        find_cost(predictions, X_train, X_test, y_train, y_test)\n",
    "        print (\"Accuracy of {} is {} %\".format(name, round((accuracy)*100, 5)))\n",
    "\n",
    "        return predictions, accuracy/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from dat fil\n",
    "X_train, X_test, y_train, y_test = reset_data(with_undersampling=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define \"classifiers\" to be used\n",
    "\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(criterion=\"entropy\", n_estimators=50),\n",
    "#     \"Extra Trees\": ExtraTreesClassifier(n_estimators=250, random_state=0),\n",
    "#     \"Naive Bayes\": GaussianNB(),\n",
    "#     # \"SVC\": SVC(),\n",
    "#     #\"KNeighborsClassifier\": KNeighborsClassifier(3),\n",
    "#     #\"GaussianProcessClassifier\": GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "#     'L1 logistic': LogisticRegression(C=C, penalty='l1'),\n",
    "#     'L2 logistic (OvR)': LogisticRegression(C=C, penalty='l2'),\n",
    "#     'Linear SVC': SVC(kernel='linear', C=C, probability=True,\n",
    "#                      random_state=0),\n",
    "#     'L2 logistic (Multinomial)': LogisticRegression(\n",
    "#     C=C, solver='lbfgs', multi_class='multinomial'),\n",
    "#     'GPC': GaussianProcessClassifier(kernel)\n",
    "}\n",
    "\n",
    "# Pickle trained models\n",
    "for name, classifier in classifiers.items():\n",
    "    feature_selection(X_train,y_train)\n",
    "    predictions, accuracy = execute_classifier(True, classifier, X_train, X_test, y_train, y_test, feat_cols, name=name)\n",
    "    print (\"Accuracy of {} is {} %\".format(name, round((accuracy)*100, 5)))\n",
    "    #with open('{}.pickle'.format(name), 'wb') as f:\n",
    "       # pickle.dump(classifier, f, pickle.HIGHEST_PROTOCOL) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
